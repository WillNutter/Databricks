{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7519482-c37b-448b-a810-791c60bf4935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 1: Import Libraries & Load Data from Silver Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6556873d-615d-4684-be05-9b5658ca4461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load silver curated table\n",
    "df = spark.table(\"workspace.silver.stedi_step_curated\")\n",
    "\n",
    "# Convert step_label to binary label\n",
    "df_labeled = df.withColumn(\n",
    "    \"label\",\n",
    "    when(col(\"step_label\") == \"step\", 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Select categorical feature + label\n",
    "df_selected = df_labeled.select(\"sensor_type\", \"label\")\n",
    "\n",
    "# Drop rows where sensor_type is null (should be minimal)\n",
    "df_selected_clean = df_selected.dropna()\n",
    "\n",
    "# Convert to pandas\n",
    "pdf = df_selected_clean.toPandas()\n",
    "\n",
    "# One-hot encode categorical feature\n",
    "X = pd.get_dummies(pdf[[\"sensor_type\"]], drop_first=True)\n",
    "y = pdf[\"label\"]\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Required shape output for rubric\n",
    "print(\"Data loaded successfully from silver catalog\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e939ffc-1b5e-4562-806e-8be49681b125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 2: Train Logistic Regression (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "302d7865-2b89-4b8f-81ef-508903b1b8d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression baseline\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ee0c100-d143-410b-aa3b-ad6a39baae41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "BLOCK 3: Train Random Forest (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb5df727-e219-417c-ae0e-c8529bfdabea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train Random Forest baseline\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "print(f\"Random Forest Accuracy: {rf_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3195dc25-bb09-4fbc-bac6-7624b4038234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 4: Compare Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab72a47d-92fe-4bdd-a035-1c4c0564772c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "\n",
    "# Display in DataFrame for clarity\n",
    "results_df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Accuracy\"])\n",
    "results_df.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7c1c704-c5fe-4558-894f-bde4cae3daf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 5: Save Trained Models (For Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a52672-8041-4253-ac2c-328392a96176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save models to GitHub repo\n",
    "MODEL_DIR = \"/Workspace/Repos/win185@ensign.edu/Databricks/models/\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "joblib.dump(log_reg, MODEL_DIR + \"logistic_regression_model.pkl\")\n",
    "joblib.dump(rf, MODEL_DIR + \"random_forest_model.pkl\")\n",
    "\n",
    "# Optional: Zip them for upload\n",
    "import shutil\n",
    "shutil.make_archive(MODEL_DIR + \"baseline_models\", 'zip', MODEL_DIR)\n",
    "\n",
    "print(\"Models saved and zipped for submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -4505756277358266,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74268d5b-a1f2-44ae-b74e-7c644b4927d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 6: Baseline Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -4505756277358266,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78764490-1e3c-4cf2-b688-4dd3e8c5ff0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline Model Evaluation\n",
    "\n",
    "### Which baseline model performed better?\n",
    "The **Random Forest** model performed better than Logistic Regression.  \n",
    "- **Random Forest Accuracy**: 0.91  \n",
    "- **Logistic Regression Accuracy**: 0.83  \n",
    "Random Forest achieved a higher accuracy due to its ability to handle non-linear patterns and interactions in the feature data.\n",
    "\n",
    "### Which model seems more stable for noisy sensor data?\n",
    "**Random Forest** is more stable for noisy data.  \n",
    "It uses an ensemble of decision trees and reduces overfitting by averaging results, making it robust to variations in the data compared to the single-line decision boundary used by Logistic Regression.\n",
    "\n",
    "### Why do the accuracy numbers differ?\n",
    "1. Logistic Regression assumes linear separability, which may not reflect the true distribution of step detection.\n",
    "2. Random Forest can capture complex, non-linear relationships in the sensor data.\n",
    "\n",
    "### Why is testing important and who could be affected?\n",
    "Testing ensures the model generalizes well to unseen data.  \n",
    "If untested, false predictions could:\n",
    "- Misclassify a user as ready for physical activity when they are not\n",
    "- Affect medical recommendations or device behaviors for users\n",
    "\n",
    "### Why does fairness matter in data science and discipleship?\n",
    "In data science, fairness means not biasing predictions against any group due to flawed data or models.  \n",
    "In discipleship, fairness reflects Christlike compassion — giving everyone an equal chance to grow and be understood.  \n",
    "Both require humility, accountability, and constant evaluation.\n",
    "\n",
    "> “By small and simple things are great things brought to pass.” – Alma 37:6\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.4 Rebuilt with Bronze and Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
