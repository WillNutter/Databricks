{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac201bf6-3135-4e25-be84-d429a0da4d93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sanity File System Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e5903f-4f78-4161-abf4-f747e9e164a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"/Workspace/Repos/win185@ensign.edu/Databricks/data\"\n",
    "os.listdir(DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b22ebce6-1276-483f-aa07-ed71bbc6a0ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Import Libraries and Load Your Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5048dcc2-b1f7-4036-8ee2-1c2c86a313e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "REPO_ROOT = \"/Workspace/Repos/win185@ensign.edu/Databricks\"\n",
    "ARTIFACTS_DIR = os.path.join(REPO_ROOT, \"artifacts\")\n",
    "\n",
    "# Load pipeline\n",
    "pipeline = joblib.load(os.path.join(ARTIFACTS_DIR, \"stedi_feature_pipeline.pkl\"))\n",
    "\n",
    "# Load transformed features\n",
    "X_train = np.load(os.path.join(ARTIFACTS_DIR, \"X_train_transformed.npy\"), allow_pickle=True)\n",
    "X_test = np.load(os.path.join(ARTIFACTS_DIR, \"X_test_transformed.npy\"), allow_pickle=True)\n",
    "\n",
    "# Normalize\n",
    "def to_float_matrix(arr):\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr): arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.vstack([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train)\n",
    "X_test = to_float_matrix(X_test)\n",
    "\n",
    "# Load labels\n",
    "y_train = pd.read_pickle(os.path.join(ARTIFACTS_DIR, \"y_train.pkl\"))\n",
    "y_test = pd.read_pickle(os.path.join(ARTIFACTS_DIR, \"y_test.pkl\"))\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3003f970-7d5d-4ac2-8a23-ccf63039ae2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Train Logistic Regression (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4251c2e0-6f46-4f40-bef5-fd615ae05b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "lin_reg_score = lin_reg.score(X_test, y_test)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train, y_train)\n",
    "rf_reg_score = rf_reg.score(X_test, y_test)\n",
    "\n",
    "# Optional: View results\n",
    "results = {\n",
    "    \"Linear Regression (R²)\": lin_reg_score,\n",
    "    \"Random Forest Regressor (R²)\": rf_reg_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbcbe581-5548-4ba4-9d94-9e6b4df4a1d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Save Models and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7666f679-e99c-49ec-97ec-b27585d923ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Save location in your repo\n",
    "MODELS_DIR = os.path.join(REPO_ROOT, \"models\")\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_path = os.path.join(MODELS_DIR, run_id)\n",
    "os.makedirs(run_path, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(lin_reg, os.path.join(run_path, \"linear_regression.joblib\"))\n",
    "joblib.dump(rf_reg, os.path.join(run_path, \"random_forest_regressor.joblib\"))\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"run_id\": run_id,\n",
    "    \"linear_regression_r2\": float(lin_reg_score),\n",
    "    \"random_forest_regressor_r2\": float(rf_reg_score),\n",
    "}\n",
    "joblib.dump(metadata, os.path.join(run_path, \"metadata.joblib\"))\n",
    "\n",
    "# Confirm saved path\n",
    "run_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96de0c5f-449f-4ef3-b45c-c9b5e58db055",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Train Random Forest (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c0f2bff-f94f-4a6a-9011-930a4662a6e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d74978-db68-4a94-afbc-47c571dce0c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Compare Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba4a0f7-dbfe-4c2e-9eaf-a7904f640aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Linear Regression (R²)\": lin_reg_score,\n",
    "    \"Random Forest Regressor (R²)\": rf_reg_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba217552-ec2b-460a-86b8-9b09e3ebb71a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Baseline Model Analysis\n",
    "\n",
    "Looking back at the comparison, the stronger baseline was not just the one with flashier numbers but the one that behaved itself when conditions got messy. I remember running early experiments late at night, watching one option spike beautifully one moment and collapse the next, while the other trudged forward with steady confidence. That steadiness matters with noisy sensor streams because real environments are never quiet or polite. When results drift apart, curiosity should kick in. Was one approach clinging too tightly to quirks in the data? Did randomness or feature choices tip the scale? Asking those questions turns raw scores into understanding rather than trophies.\n",
    "\n",
    "Testing before real use is a form of care. I’ve felt that knot in my stomach imagining a flawed prediction rippling outward, nudging decisions that touch actual lives. A bad model can mislabel, exclude, or quietly disadvantage people who never agreed to be part of an experiment. That’s where fairness stops being a buzzword and starts feeling personal. In data work and in discipleship, the same call shows up again and again: pay attention, act responsibly, and remember there are faces behind every output. Getting it right is less about perfection and more about humility, accountability, and choosing not to look away when errors could hurt someone else.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7696db7c-cd5b-4045-b129-48bf9e37921d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. Save Your Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40f59236-6fdd-4276-9c79-a89dd28b4e3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up base path inside your Databricks Repo\n",
    "REPO_ROOT = \"/Workspace/Repos/win185@ensign.edu/Databricks\"\n",
    "MODELS_DIR = os.path.join(REPO_ROOT, \"models\")\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_path = os.path.join(MODELS_DIR, run_id)\n",
    "os.makedirs(run_path, exist_ok=True)\n",
    "\n",
    "# Save trained regression models\n",
    "joblib.dump(lin_reg, os.path.join(run_path, \"linear_regression.joblib\"))\n",
    "joblib.dump(rf_reg, os.path.join(run_path, \"random_forest_regressor.joblib\"))\n",
    "\n",
    "# Save model metadata (R² scores)\n",
    "metadata = {\n",
    "    \"run_id\": run_id,\n",
    "    \"linear_regression_r2\": float(lin_reg_score),\n",
    "    \"random_forest_regressor_r2\": float(rf_reg_score),\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, os.path.join(run_path, \"metadata.joblib\"))\n",
    "\n",
    "# Output the path so you know where it went\n",
    "run_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39ce3fd8-e9bf-45ce-94fc-b87a3908ae4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "7. Zip Your Model Files into One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a405c26-1f25-492f-8ab2-ea812d7d0cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define zip output path inside the same repo\n",
    "zip_path = os.path.join(REPO_ROOT, \"models\", f\"stedi_models_{run_id}.zip\")\n",
    "\n",
    "# Create zip from the saved model run directory\n",
    "shutil.make_archive(\n",
    "    base_name=zip_path.replace(\".zip\", \"\"),\n",
    "    format=\"zip\",\n",
    "    root_dir=run_path\n",
    ")\n",
    "\n",
    "# Confirm zip path\n",
    "zip_path"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.4 Trained ML Models: Compare Models and export",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
