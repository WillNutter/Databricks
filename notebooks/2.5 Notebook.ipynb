{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b03fe336-734d-4ce0-8da9-012e96b92f45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# STEDI Step Test – GitHub Repository Lab\n",
    "\n",
    "This notebook completes the STEDI Step Test ETL using **pure Python**\n",
    "due to restricted Spark and filesystem permissions.\n",
    "\n",
    "Data is loaded directly from the Databricks Repo workspace path:\n",
    "\n",
    "/workspace/repos/win185@ensign.edu/Databricks/logs\n",
    "\n",
    "The workflow includes data import, cleaning, joins, feature engineering,\n",
    "visual validation, and ethical reflection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d907c6-154b-416e-aafe-78ea88721745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba41c5b-21bc-4896-8bee-7030a7dd9c37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load raw device message and rapid step test data directly from the\n",
    "Databricks Repo directory using Python file reads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56f55dff-7788-4d31-980c-15fcf038c604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "device_df = pd.read_parquet(\n",
    "    \"/Workspace/Repos/win185@ensign.edu/Databricks/data/device_messages.parquet\"\n",
    ")\n",
    "\n",
    "step_test_df = pd.read_parquet(\n",
    "    \"/Workspace/Repos/win185@ensign.edu/Databricks/data/rapid_step_tests.parquet\"\n",
    ")\n",
    "\n",
    "print(\"device_df:\")\n",
    "print(device_df.head())\n",
    "\n",
    "print(\"\\nstep_test_df:\")\n",
    "print(step_test_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903e0c97-20dc-4658-91ee-9b5862f62cb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Confirm both datasets loaded successfully and contain valid records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "463bc520-961c-4099-9a24-3c3ecf21e149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "device_df.info()\n",
    "step_test_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b36a1cb-a1a1-4b30-babe-752567a5ac87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Convert string timestamps into datetime objects to support\n",
    "time-based analysis and proper joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "085614d8-9617-4fd3-af5f-7cac8c8705f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df = pd.merge(\n",
    "    device_df,\n",
    "    step_test_df,\n",
    "    on=\"device_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "joined_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378f9afe-f4a0-4f4b-b4c5-fd37fe9e2df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aggregate accelerometer data per device to create analytical features,\n",
    "including average, minimum, and maximum values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e93be4f8-204c-4dfc-ae62-810b04e63b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Clean numeric columns ---\n",
    "\n",
    "# Distance: remove units and convert to float\n",
    "joined_df[\"distance\"] = (\n",
    "    joined_df[\"distance\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\"cm\", \"\", regex=False)\n",
    "        .astype(float)\n",
    ")\n",
    "\n",
    "# Step-related fields: ensure numeric\n",
    "joined_df[\"total_steps\"] = pd.to_numeric(joined_df[\"total_steps\"], errors=\"coerce\")\n",
    "joined_df[\"step_points\"] = pd.to_numeric(joined_df[\"step_points\"], errors=\"coerce\")\n",
    "\n",
    "# --- Aggregate features per device ---\n",
    "\n",
    "features_df = (\n",
    "    joined_df\n",
    "        .groupby(\"device_id\")\n",
    "        .agg(\n",
    "            avg_distance=(\"distance\", \"mean\"),\n",
    "            min_distance=(\"distance\", \"min\"),\n",
    "            max_distance=(\"distance\", \"max\"),\n",
    "            total_steps=(\"total_steps\", \"max\"),\n",
    "            step_points=(\"step_points\", \"max\")\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770ebe35-6894-4275-96e3-32dfc4133d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Plot accelerometer X-axis values for a single device to visually\n",
    "verify sensor behavior and data continuity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15b4f73f-8c65-4501-b822-23804cf78048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select one device to visualize\n",
    "sample_device = features_df[\"device_id\"].iloc[0]\n",
    "\n",
    "# Filter and sort data for that device\n",
    "plot_df = (\n",
    "    joined_df[joined_df[\"device_id\"] == sample_device]\n",
    "    .sort_values(\"timestamp\")\n",
    ")\n",
    "\n",
    "# Plot distance over time\n",
    "plt.figure()\n",
    "plt.plot(plot_df[\"timestamp\"], plot_df[\"distance\"])\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Distance (cm)\")\n",
    "plt.title(f\"Device {sample_device} – Distance Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1a1e4b-b9e5-48cb-af49-c85b857feea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reflection\n",
    "\n",
    "Loading data directly from the Databricks Repo path was straightforward\n",
    "but I could not get pyspark to work. Note: Due to restricted Spark permissions in this environment, SQL queries are presented for logic and documentation, while equivalent transformations are executed using Python (pandas).I generated a python set of code that works around this issue. The most confusing aspect was ensuring timestamps were properly converted before joining datasets. An ethical risk is assuming sensor data accuracy, which could result in misleading conclusions if device errors or biases are not detected.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.5 Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
